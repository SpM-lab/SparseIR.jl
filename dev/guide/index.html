<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Guide · SparseIR.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/custom.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">SparseIR.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Guide</a><ul class="internal"><li><a class="tocitem" href="#Problem-statement"><span>Problem statement</span></a></li><li><a class="tocitem" href="#Treatment"><span>Treatment</span></a></li></ul></li><li><a class="tocitem" href="../public/">Public</a></li><li><a class="tocitem" href="../private/">Private</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Guide</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Guide</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/SpM-lab/SparseIR.jl/blob/main/docs/src/guide.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="guide"><a class="docs-heading-anchor" href="#guide">Example usage and detailed explanation</a><a id="guide-1"></a><a class="docs-heading-anchor-permalink" href="#guide" title="Permalink"></a></h1><p>We will explain the inner workings of <code>SparseIR.jl</code> by means of an example use case, adapted from the <a href="https://arxiv.org/abs/2206.11762"><code>sparse-ir</code> paper</a>.</p><h2 id="Problem-statement"><a class="docs-heading-anchor" href="#Problem-statement">Problem statement</a><a id="Problem-statement-1"></a><a class="docs-heading-anchor-permalink" href="#Problem-statement" title="Permalink"></a></h2><blockquote><p>Let us perform self-consistent second-order perturbation theory for the single impurity Anderson model at finite temperature. Its Hamiltonian is given by</p><p class="math-container">\[    H = U c^\dagger_\uparrow c^\dagger_\downarrow c_\downarrow c_\uparrow + \sum_{p\sigma} \big(V_{p\sigma}  f_{p\sigma}^\dagger c_\sigma + V_{p\sigma}^* c_\sigma^\dagger c_\sigma^\dagger\big) + \sum_{p\sigma} \epsilon_{p} f_{p\sigma}^\dagger f_{p\sigma}\]</p><p>where <span>$U$</span> is the electron interaction strength, <span>$c_\sigma$</span> annihilates an electron on the impurity, <span>$f_{p\sigma}$</span> annihilates an electron in the bath, <span>$\dagger$</span> denotes the Hermitian conjugate, <span>$p\in\mathbb R$</span> is bath momentum, and <span>$\sigma\in\{\uparrow, \downarrow\}$</span> is spin. The hybridization strength <span>$V_{p\sigma}$</span> and bath energies <span>$\epsilon_p$</span> are chosen such that the non-interacting density of states is semi-elliptic with a half-bandwidth of one, <span>$\rho_0(\omega) = \frac2\pi\sqrt{1-\omega^2}$</span>, <span>$U=1.2$</span>, <span>$\beta=10$</span>, and the system is assumed to be half-filled.</p></blockquote><h2 id="Treatment"><a class="docs-heading-anchor" href="#Treatment">Treatment</a><a id="Treatment-1"></a><a class="docs-heading-anchor-permalink" href="#Treatment" title="Permalink"></a></h2><p>We first import <code>SparseIR</code> and construct an appropriate basis (<span>$\omega_\mathrm{max} = 8$</span> should be more than enough for this example):</p><pre><code class="language-julia-repl hljs">julia&gt; using SparseIR

julia&gt; basis = FiniteTempBasis(fermion, 10, 8)
FiniteTempBasis{LogisticKernel, Float64}(fermion, 10.0, 8.0)</code></pre><p>There&#39;s quite a lot happening behind the scenes in this first innocuous-looking statement, so let&#39;s break it down: Because we did not specify otherwise, the constructor chose the analytic continuation kernel for fermions, <code>LogisticKernel(80.0)</code>, defined by</p><p class="math-container">\[\begin{equation}
    K(x, y) = \frac{e^{-Λ y (x + 1) / 2}}{1 + e^{-Λ y}},
\end{equation}\]</p><p>for us, where 80.0 is the value of the scale parameter <span>$\Lambda = \beta\omega_\mathrm{max}$</span>, shown below.</p><img src="../assets/img/kernel.png" alt="Logistic Kernel" width="70%" class="center"/><h3 id="SVE"><a class="docs-heading-anchor" href="#SVE">SVE</a><a id="SVE-1"></a><a class="docs-heading-anchor-permalink" href="#SVE" title="Permalink"></a></h3><p>Central is the <em>singular value expansion</em>&#39;s (SVE) computation, which is handled by the function <code>SVEResult</code>: Its purpose is constructing the decomposition</p><p class="math-container">\[\begin{equation}\label{SVE}
    K(x, y) \approx \sum_{\ell = 0}^L U_\ell(x) S_\ell V_\ell(y)
\end{equation}\]</p><p>where <span>$U_\ell(x)$</span> and <span>$V_\ell(y)$</span> are called <span>$K$</span>&#39;s left and right singular functions respectively and <span>$S_\ell$</span> are its singular values. The singular functions are form an orthonormal basis by construction, i.e.</p><p class="math-container">\[\begin{equation}
    \int \dd{x} U_\ell(x) U_{\ell&#39;}(x) = \delta_{\ell\ell&#39;} = \int \dd{y} V_\ell(y) V_{\ell&#39;}(y).
\end{equation}\]</p><p>and thus</p><p class="math-container">\[\begin{equation} \label{coeff1}
\left.
\begin{aligned}
    S_\ell U_\ell(x) &amp;= \int \dd{y} K(x, y) V_\ell(y) \\
    S_\ell V_\ell(y) &amp;= \int \dd{x} K(x, y) U_\ell(x)
\end{aligned}
\right\}
\end{equation}\]</p><p>Here and in what follows, unless otherwise indicated, integrals are taken to be over the interval <span>$[-1,1]$</span>.</p><ol><li><p>The function first calls the <code>choose_accuracy</code> helper and thereby sets the appropriate working precision. Because we did not specify a working accuracy <span>$\varepsilon$</span>, it chooses for us <span>$\varepsilon \approx 2.2 \times 10^{-16}$</span> and working type <code>Float64x2</code> - a 128 bits floating point type provided by the MultiFloats.jl package - because in computing the SVD we incur a precision loss of about half our input bits, leaving us with full double accuracy results only if we use quad precision during the computation.</p></li><li><p>Then - by calling out to the <code>CentrosymmSVE</code> constructor - a support grid <span>$\{x_i\} \times \{y_j\}$</span> the kernel will later be evaluated on is built. Along with these support points weights <span>$\{w_i\}$</span> and <span>$\{z_j\}$</span> are computed. These points and weights consist of repeated scaled Gauss integration rules, such that</p><p class="math-container">\[\begin{equation} \label{intrules}
    \int \dd{x} f(x) \approx \sum_i f(x_i) w_i
    \quad\text{and}\quad
    \int \dd{y} g(y) \approx \sum_j g(y_j) z_j.
\end{equation}\]</p><p>To get an idea regarding the distribution of these sampling points, refer to following figure, which shows <span>$\{x_i\} \times \{y_j\}$</span> for <span>$\Lambda = 80$</span>:</p><p><img src="../assets/img/sve_grid.png" alt="Sampling point distribution"/></p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The points do not cover <span>$[-1, 1] × [-1, 1]$</span> but only <span>$[0, 1] × [0, 1]$</span>. This is actually a special case as we exploit the kernel&#39;s centrosymmetry, i.e. <span>$K(x, y) = K(-x, -y)$</span>. It is straightforward to show that the left/right singular vectors then can be chosen as either odd or even functions.</p><p>Consequentially, they are singular functions of a reduced kernel <span>$K^\mathrm{red}_\pm$</span> on <span>$[0, 1] × [0, 1]$</span> that is given as either:</p><p class="math-container">\[\begin{equation}
    K^\mathrm{red}_\pm(x, y) = K(x, y) \pm K(x, -y)
\end{equation}\]</p><p>It is these reduced kernels we will actually sample from, gaining a 4-fold speedup in constructing the SVE. <img src="../assets/img/kernel_red.png" alt="abc"/></p></div></div><p>Using the integration rules \eqref{intrules} allows us to approximate \eqref{coeff1} by</p><p class="math-container">\[\begin{equation} \label{coeff2}
\left.
\begin{aligned}
    S_\ell U_\ell(x_i) &amp;\approx \sum_j K(x_i, y_j) V_\ell(y_j) z_j &amp;&amp;\forall i \\
    S_\ell V_\ell(y_j) &amp;\approx \sum_i K(x_i, y_j) U_\ell(x_i) w_i &amp;&amp;\forall j
\end{aligned}
\right\}
\end{equation}\]</p><p>which we now multiply by <span>$\sqrt{w_i}$</span> and <span>$\sqrt{z_j}$</span> respectively, yielding</p><p class="math-container">\[\begin{equation} \label{coeff3}
\left.
\begin{aligned}
    S_\ell \sqrt{w_i} U_\ell(x_i) &amp;\approx \sum_j \sqrt{w_i} K(x_i, y_j) \sqrt{z_j} \sqrt{z_j} V_\ell(y_j) \\
    S_\ell \sqrt{z_j} V_\ell(y_j) &amp;\approx \sum_i \sqrt{w_i} K(x_i, y_j) \sqrt{z_j} \sqrt{w_i} U_\ell(x_i)
\end{aligned}
\right\}
\end{equation}\]</p><p>If we now define vectors <span>$\vec u_\ell$</span>, <span>$\vec v_\ell$</span> and a matrix <span>$K$</span> with entries <span>$u_{\ell, i} \equiv \sqrt{w_i} U_\ell(x_i)$</span>, <span>$v_{\ell, j} \equiv \sqrt{z_j} V_\ell(y_j)$</span> and <span>$K_{ij} \equiv \sqrt{w_i} K(x_i, y_j) \sqrt{z_j}$</span>, then</p><p class="math-container">\[\begin{equation} \label{coeff4}
\left.
\begin{aligned}
    S_\ell u_{\ell, i} &amp;\approx \sum_j K_{ij} v_{\ell, j} \\
    S_\ell v_{\ell, j} &amp;\approx \sum_i K_{ij} u_{\ell, i}
\end{aligned}
\right\}
\end{equation}\]</p><p>or</p><p class="math-container">\[\begin{equation} \label{coeff5}
\left.
\begin{aligned}
    S_\ell \vec u_\ell &amp;\approx K^\phantom{\mathrm{T}} \vec v_\ell \\
    S_\ell \vec v_\ell &amp;\approx K^\mathrm{T} \vec u_\ell.
\end{aligned}
\right\}
\end{equation}\]</p><p>Together with the property <span>$\vec u_\ell^\mathrm{T} \vec u_{\ell&#39;} \approx \delta_{\ell\ell&#39;} \approx \vec v_\ell^\mathrm{T} \vec v_{\ell&#39;}$</span> we have successfully translated the original SVE problem into an SVD, because</p><p class="math-container">\[    K = \sum_\ell S_\ell \vec u_\ell \vec v_\ell^\mathrm{T}.\]</p></li><li><p>The next step is calling the <code>matrices</code> function which computes the matrix <span>$K$</span> derived in the previous step.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>The function is named in the plural because in the centrosymmetric case it actually returns two matrices <span>$K_+$</span> and <span>$K_-$</span>, one for the even and one for the odd kernel. These matrices&#39; SVDs are later concatenated, so for simplicity, we will refer to <span>$K$</span> from here on out.</p></div></div><div class="admonition is-info"><header class="admonition-header">Info</header><div class="admonition-body"><p>Special care is taken here to avoid FP-arithmetic cancellation around <span>$x = -1$</span> and <span>$x = +1$</span>.</p></div></div><p><img src="../assets/img/kernel_red_matrices.png" alt="Kernel matrices"/> Note that in the plot, the matrices are rotated 90 degrees to the left to make the connection with the (subregion <span>$[0, 1] × [0, 1]$</span> of the) previous figure more obvious. Thus we can see how the choice of sampling points has magnified and brought to the matrices&#39; centers the regions of interest. Furthermore, elements with absolute values smaller than <span>$10\%$</span> of the maximum have been omitted to emphasize the structure; this should however not be taken to mean that there is any sparsity to speak of we could exploit in the next step.</p></li><li><p>Take the truncated singular value decompostion (TSVD) of <span>$K$</span>, or rather, of <span>$K_+$</span> and <span>$K_-$</span>. We use here a custom TSVD routine written by Markus Wallerberger which combines a homemade rank-revealing QR decomposition with <code>GenericLinearAlgebra.svd!</code>. This is necessary because there is currently no TSVD for arbitrary types available.</p></li><li><p>Via the function <code>truncate</code>, we throw away superfluous terms in our expansion. More specifically, we choose <span>$L$</span> in \eqref{SVE} such that <span>$S_\ell / S_0 &gt; \varepsilon$</span> for all <span>$\ell \leq L$</span>. Here <span>$\varepsilon$</span> is our selected precision, in our case it&#39;s equal to the double precision machine epsilon, <span>$2^{-52} \approx 2.22 \times 10^{-16}$</span>.</p></li></ol></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../public/">Public »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Wednesday 30 November 2022 09:04">Wednesday 30 November 2022</span>. Using Julia version 1.8.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
